{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimating a Language Model from Data**\n",
    "---\n",
    "\n",
    "本来、言語モデルの目的はなんらかの真の求めたい確率分布$P$ (人間の好みに基づいた確率など)があって、それから降ってきたsamples $D$があって、その$D$を使って、パラメータ化された$P_\\theta$の言語モデルを最適化していくことである。\n",
    "\n",
    "この章を進めるにあたって、以下の仮定などを用いて、話を進めるらしい。\n",
    "\n",
    "# ![](https://i.gyazo.com/13653aa591db22b1d2a0474739a45987.png)\n",
    "\n",
    "データのsamplesは互いに独立だよって意味。\n",
    "\n",
    "# ![](https://i.gyazo.com/50205b2f39466316e79e0115fc12e734.png)\n",
    "\n",
    "パラメータ化された言語モデルの中に、最適な言語モデルを表せるような$\\theta$が存在しているよってこと。\n",
    "\n",
    "- n-gram モデルの場合 (直前のn-1個の条件付き確率で決まる)\n",
    "\n",
    "\n",
    "  語彙サイズを $|\\Sigma|$、モデル次数を $n$ とすると，\n",
    "  $$\n",
    "    \\Theta_{\\mathrm{n\\text{-}gram}}\n",
    "    = \\underbrace{\\Delta^{|\\Sigma|}\\times\\Delta^{|\\Sigma|}\\times\\cdots\\times\\Delta^{|\\Sigma|}}_{|\\Sigma|^{\\,n-1}\\text{ 個}}\n",
    "    \\,,\n",
    "  $$\n",
    "  ここで $\\Delta^{|\\Sigma|}$ は\n",
    "  $$\n",
    "    \\Delta^{|\\Sigma|} = \\Bigl\\{\\,\\mathbf{p}=(p_1,\\dots,p_{|\\Sigma|})\\in\\mathbb{R}^{|\\Sigma|}\\;\\Big|\\;\\sum_{i=1}^{|\\Sigma|}p_i=1,\\;p_i\\ge0\\Bigr\\}\n",
    "  $$\n",
    " \n",
    "- ニューラルネットワークの場合\n",
    "  $L$ 層のネットワークを考えると，パラメータは各層の重み行列とバイアスの全体集合です．\n",
    "  $$\n",
    "    \\Theta_{\\mathrm{NN}}\n",
    "    = \\bigl\\{\\,(\\mathbf{W}^{(1)},\\mathbf{b}^{(1)},\\dots,\\mathbf{W}^{(L)},\\mathbf{b}^{(L)})\\;\\big|\\;\n",
    "    \\mathbf{W}^{(L)}\\in\\mathbb{R}^{d_{L}\\times d_{L-1}},\\;\n",
    "    \\mathbf{b}^{(L)}\\in\\mathbb{R}^{d_L}\n",
    "    \\bigr\\}.\n",
    "  $$\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**一般的にどう擬似最適解を求めていくか**\n",
    "\n",
    "$l$を損失関数, $\\theta^*$を最適なパラメータとすると、以下のような式で求めていく。\n",
    "\n",
    "$$\n",
    "\\widehat{\\boldsymbol{\\theta}} \\stackrel{\\text { def }}{=} \\underset{\\boldsymbol{\\theta} \\in \\Theta}{\\operatorname{argmin}} \\ell\\left(\\boldsymbol{\\theta}^*, \\boldsymbol{\\theta}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もし、事前に$\\theta^*$がわかっているなら、簡単なわけだけど、そんなわけないので、私たちは$\\theta^*$から作られたであろうデータ$\\mathcal{D}$から擬似的な$P_{\\theta^*}$を求めていけばいいよね。\n",
    "\n",
    "そこから、cross-entropyとかKL-divergenceとかで近づけていく。\n",
    "\n",
    "それか、学習する$P_{\\theta}$を最大尤度の式を使って学習する。\n",
    "\n",
    "$$\n",
    "L(\\boldsymbol{\\theta})=\\prod_{n=1}^N p_\\theta\\left(\\boldsymbol{y}^{(n)}\\right) .\n",
    "$$\n",
    "\n",
    "# ![](https://i.gyazo.com/4ede1eefe6dbd4f21087389c28d1f8a0.png)\n",
    "\n",
    "最大尤度は実質的に最適分布をδ分布で表した時の、cross-entropyと同じ作用になるらしい、証明わかりやすかった。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "上で述べたやつはそれまでの文脈を使ってたけど、文脈の前後を考慮するMasked Language Modelingっていうやり方もあるよ。\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\mathrm{HLM}}(\\boldsymbol{\\theta})=\\sum_{n=1}^N \\sum_{t=1}^T \\log p_\\theta\\left(y_t^{(n)} \\mid \\boldsymbol{y}_{<t}^{(n)}, \\boldsymbol{y}_{>t}^{(n)}\\right)\n",
    "$$\n",
    "\n",
    "# ![](https://i.gyazo.com/5427d7acce78c5882639585fb521c56f.png)\n",
    "\n",
    "上の定理に基づいたDPOの解析とかできたら面白いけどもうやられてたりするかも？"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
